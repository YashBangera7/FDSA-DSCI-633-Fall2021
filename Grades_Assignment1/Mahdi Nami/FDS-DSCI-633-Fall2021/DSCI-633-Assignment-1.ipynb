{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIT DSCI-633: Foundations of Data Science and Analytics\n",
    "## Assignment 1\n",
    "### Due: 11:59 pm EST, Saturday, Oct 2, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (10 points)\n",
    "\n",
    "In statistics and probability theory, the law of large numbers is a theorem that describes the result of\n",
    "repeating the same experiment a large number of times. The theorem states that if the same\n",
    "experiment or study is repeated independently a large number of times, the average of the results of\n",
    "the trials must be close to the expected value. The result becomes closer to the expected value as the\n",
    "number of trials is increased. Let us look at a specific experiment.\n",
    "\n",
    "Assume you have a Gaussian distribution (commonly called a “bell curve”) with mean µ and std\n",
    "deviation σ. The area under the curve that lies between σ and 2σ, and –σ and -2σ is approximately\n",
    "27.2%. In other words, approximately 27.2% of numbers generated randomly using this distribution will\n",
    "fall in the range [µ + σ, µ + 2σ] or [µ - 2σ, µ - σ], as shown below.\n",
    "\n",
    "Generate N random numbers that follow a Gaussian distribution with µ = 100, σ = 10, and count the\n",
    "numbers M that fall into the ranges above. Print the fraction M/N. Repeat this for N = 10, 100, 1000,\n",
    "10000, and 1000000.\n",
    "\n",
    "Does the fraction start to approach 27.2%?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy under alias np used to work with array referingto numpy package as np from now non\n",
    "import numpy as np \n",
    "# import panda under alias pd used to work with data refering to panda package as pd from now on\n",
    "import pandas as pd\n",
    "# import matplotlib package and using .pyplot to provide matalb-like way of plotting\n",
    "# importing them under alias plt which will be refered to as from now\n",
    "# \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# mean = 100\n",
    "mean = 100\n",
    "# standard deviatio = 10\n",
    "stdd = 10\n",
    "\n",
    "# defining function called test with parameter N = 10, 100, 1000, 10000, and 1000000    \n",
    "def test(N):\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
    "# using random.normal() method to get a Normal Data Distribution (loc = mean = peak of bell, scale = stdd = how flath the graph distribution should be, size = N = shpae of returned array)\n",
    "    r=np.random.normal(mean,stdd,N)\n",
    "    u1 = mean + 2*stdd \n",
    "    d1 = mean - 2*stdd\n",
    "    u2 = mean + stdd\n",
    "    d2 = mean - stdd\n",
    "    M1 = sum((r>u2) * (r<u1))\n",
    "    M2 = sum((r<d2) * (r>d1))\n",
    "    M = M1 + M2\n",
    "    return M/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5    , 0.26   , 0.256  , 0.2704 , 0.27114])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ns = [10, 100, 1000, 10000, 1000000]\n",
    "frac = np.zeros(5)\n",
    "for path in np.arange(5):\n",
    "    frac[path] = test(Ns[path])\n",
    "    \n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Correct : 10 points </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (5 points)\n",
    "\n",
    "Imagine you have a dataset of movie ratings for a set of 500 popular movies and a set of 1000 users.\n",
    "Each data sample contains the ratings of each movie (from 1 to 5 stars) by a specific user. The rating is\n",
    "an integer in the range [0,5], with a value of 0 means that the user did not watch that movie.\n",
    "How would you convert this data to a form suitable for association analysis? In particular, what type of\n",
    "attributes would you have and how many of them?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of movie ratings (from 1 to 5 stars = int w/ range [0,5] )\n",
    "set of 500 popular movies\n",
    "set of 1000 users \n",
    "Each data sample = ratings of each movie by a specific user\n",
    "0 means that the user did not watch that movie\n",
    "1. How convert this data to suitable form for association analysis? \n",
    "2. what type of attributes would have and how many?\n",
    "\n",
    "\n",
    "Ref: https://www.geeksforgeeks.org/understanding-data-attribute-types-qualitative-and-quantitative/\n",
    "\n",
    "\n",
    "\n",
    "Q2) Attribute 1: Users, Totoal = 1000\n",
    "Discrete: since there 1000 users, and finite numerical value\n",
    "Ordinal: meaningful ranking(order) between (user1, user2,...user1000)\n",
    "Nominal: values of nominal attributes are names (mahdi, jack)\n",
    "\n",
    "    Attribute 2: Movies, Total = 500\n",
    "Discrete Attribute: finite numeric values (500 only)\n",
    "Ordinal: meaningful ranking(order) b/w them (movie1, movie2,...movie500)\n",
    "Binary: 0 means that the user did not watch that movie, so user was absent\n",
    "Nominal: values of nominal attributes are names (starwars, fast5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════╤═════════╤═════════════╤══════════╤═══════╕\n",
      "│ ID   │ Users   │ Star Wars   │ Fast 5   │ ...   │\n",
      "╞══════╪═════════╪═════════════╪══════════╪═══════╡\n",
      "│      │ Mahdi   │ 0           │ 1        │ ....  │\n",
      "├──────┼─────────┼─────────────┼──────────┼───────┤\n",
      "│ 1    │ Jack    │ 2           │ 4        │ ....  │\n",
      "├──────┼─────────┼─────────────┼──────────┼───────┤\n",
      "│ 2    │ Johnx3  │ 5           │ 2        │ ....  │\n",
      "├──────┼─────────┼─────────────┼──────────┼───────┤\n",
      "│ 3    │ M       │ ....        │ ....     │ ....  │\n",
      "├──────┼─────────┼─────────────┼──────────┼───────┤\n",
      "│ .... │         │             │          │       │\n",
      "├──────┼─────────┼─────────────┼──────────┼───────┤\n",
      "│ 1000 │         │             │          │       │\n",
      "╘══════╧═════════╧═════════════╧══════════╧═══════╛\n"
     ]
    }
   ],
   "source": [
    "## Q1 >> converting data for suitable form for association analysis\n",
    "from tabulate import tabulate\n",
    "info = {'ID': ['',1,2,3, '....', 1000],'Users': ['Mahdi', 'Jack', 'Johnx3', 'M'], 'Star Wars': [0,2,5, '....'],'Fast 5': [1,4,2, '....'],'...': ['....','....','....', '....']}\n",
    "\n",
    "print(tabulate(info, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'> Incorrect :0 points </font> \n",
    "For association analysis, we require binary asymmetric attributes.\n",
    "\n",
    "Since each rating can take 6 possible values, we would need to replace it with 6 asymmetric binary attributes\n",
    "of the form (rating == 0?) (rating == 1?) ...\n",
    "\n",
    "This will give us 500 x 6 = **3000 binary attributes per user**.  \n",
    "The resulting sparse data matrix would be **1000 rows x 3000 columns**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 (5 points)\n",
    "\n",
    "Distinguish between noise and outliers\n",
    "\n",
    "1. True or False ? Noise may be in the form of noisy attribute values, or noise objects.\n",
    "2. True or False ? Noise is sometimes desirable.\n",
    "3. True or False ? Outliers are sometimes desirable.\n",
    "4. True or False ? Noise objects may or may not be outliers. Explain your reasoning.\n",
    "5. True or False ? Outlier objects may or may not be noise. Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. true, attributes are what describe data objects so if they all have noise then entire data objects will have noise\n",
    "\n",
    "\n",
    "2. false, noise in data refer to data corruption or when system cannont understand, creates troubles for machine learning algorithms becuase it can think of noise as pattern. It also increase amount of storage space\n",
    "\n",
    "\n",
    "3. true, there are times the outliers need to be removed from the dataset which means they are undesireable but other times they must be kept these are for example when removing the outliers will affect the staticstical results and assumpiton and droping the outliers might casuwe regression line to move. There are times that the main objective of data minings are to identify outliers\n",
    "\n",
    "ref: https://medium.com/@aatl2012/the-basic-difference-between-noise-and-outliers-in-data-cd3ff32343e0\n",
    "\n",
    "ref: https://towardsdatascience.com/outlier-why-is-it-important-af58adbefecc\n",
    "\n",
    "ref: https://www.mathworks.com/matlabcentral/answers/54798-what-is-the-difference-between-noise-and-outlier\n",
    "\n",
    "4. True, Noise are meaningless data, whereas outliers are data with true value. The vast majority of time outliers are noise but sometimes a data point that is true signal can be an outlie\n",
    "\n",
    "5. True, the outlier might caused either by error in measurements or entered by mistake in this it is a noise and should be removed from the data. In case the outlier is an outlier it might be global, contextual or collective outlier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Correct : 5 points </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 (20 points)\n",
    "Download the ‘Diamonds’ dataset from https://www.kaggle.com/shivam2503/diamonds.\n",
    "1. Based on the description of the dataset provided at the site, categorize each attribute of the data as\n",
    "discrete or continuous, qualitative (nominal or ordinal), or quantitative (interval or ratio)  (5 points)\n",
    "e.g. Age in years: Discrete, Quantitative, Ratio.\n",
    "2. Load the CSV data file into a Pandas DataFrame object and display the first 5 rows. (2 points)\n",
    "3. Calculate summary statistics:\n",
    "a. For each quantitative attribute: find the mean, median, standard deviation, and range. (3.5 points)\n",
    "b. For each qualitative attribute, find the mode. (1.5 points)\n",
    "c. Find the Interquartile Range (IQR) of the ‘price’ variable. (0.5 points)\n",
    "4. What fraction of the data samples have ‘cut’ that is ‘very good’ or better ? Create a bar plot\n",
    "showing the distribution of the data samples by ‘cut’ (one bar for each value of cut). (2.5 points)\n",
    "5. Plot a histogram of the 'carat' variable. (2 points)\n",
    "6. Plot a scatter plot of ‘carat’ vs ‘price’. (2 points)\n",
    "7. Compute the correlation between ‘carat’ and ‘price’. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 (4 points)\n",
    "\n",
    "We have a collection of m documents.\n",
    "\n",
    "Let us say we would like to compare two documents x and y using their document term vectors. \n",
    "\n",
    "Let tf_ij be the frequency of the ith word (term) in the jth document\n",
    "\n",
    "1. Let the vocabulary size (the dimensionality of the vectors) be n. What is a good measure of similarity for this purpose ? Write the formula for it in terms of tf_ij.\n",
    "\n",
    "2. Consider the variable transformation given by idf_ij = tf_ij * log(m/df_i), where df_i is the document frequency, i.e. the number of documents in which the ith term occurs. The transformed variable idf_ij is called the inverse document frequency. What are the advantages of using this transformed variable instead of the original in the similarity computation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6 (6 points)\n",
    "\n",
    "Write Python functions to compute the Hamming (L1) distance, SMC and Jaccard similarity coefficient between two binary vectors. Use them to these proximity measures between the following vectors:\n",
    "\n",
    "x = 1010101010101 \n",
    "\n",
    "y = 1000100010001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7 (6 points)\n",
    "\n",
    "Calculate the indicated similarity or distance measures of the vectors show below (you can do this by hand or by writing code, but please show the computation either way):\n",
    "\n",
    "x = (1,1,1,1) and y = (3,3,3,3) : cosine, correlation, Euclidean\n",
    "\n",
    "x = (0,1,0,1,0,1) and y = (1,0,1,0,1,0) : cosine, correlation, Euclidean, Jaccard \n",
    "\n",
    "x = (1,1,0,1,0,1) and y = (1,1,1,0,0,1) : cosine, correlation, Lmax, Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'> Partially Correct: 4.33 </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission instructions\n",
    "\n",
    "1. Your assignment should be completed by filling in the empty solution cells in this Jupyter notebook file (.ipynb). Feel free to add more cells as needed.\n",
    "\n",
    "2. Please comment your code using either markdown or #comments and use meaningful variable names to make it as readable and intelligible as possible.\n",
    "\n",
    "3. Write your code in the form of functions. For example: \n",
    "\n",
    "    def my_code ():\n",
    "\n",
    "          #Write code here\n",
    "      \n",
    "          return \"The return value\"\n",
    "          \n",
    "\n",
    "4. If the problem is to find the value of 'x', printing 'x = (your answer)' will help us identify if your code worked.\n",
    "\n",
    "\n",
    "5. For code that refers to local data files downloaded from the internet, please keep the file path simple (e.g. ~/downloads/datafilename) so that it works on our copy of the dataset. Please do not modify either the filename or the file contents in any way.\n",
    "\n",
    "6. Solution to problems that do not require any coding can be typed up in their own cells using markdown.\n",
    "    \n",
    "7. Unless there are legitimate circumstances, late assignments will not be accepted.\n",
    "\n",
    "8. All assignments are individual.\n",
    "\n",
    "9. All the sources used for problem solution must be acknowledged, e.g. web sites, books, research papers, etc.\n",
    "\n",
    "10. Academic integrity is taken seriously; for detailed information see the RIT Honor Code and with RIT's Academic Integrity Policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Total score : 19.33 points </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
